{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/avgupta/anaconda2/bin/python2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import snap\n",
    "import collections\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pdb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import copy\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Ratings Graph Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rating = namedtuple('Rating', ['Rating', 'User', 'Object'])\n",
    "\n",
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def get_data_set():\n",
    "    movie_critic_ratings = {}\n",
    "    \n",
    "    movie_header_indeces = {}\n",
    "    for line in open('data/grouplens/movies.dat'):\n",
    "        line = line.strip()\n",
    "        if not movie_header_indeces:\n",
    "            for i, column in enumerate(line.split('\\t')):\n",
    "                movie_header_indeces[column] = i\n",
    "            continue\n",
    "        NUM_TOP_CRITICS_REVIEWS_IDX = movie_header_indeces['rtTopCriticsNumReviews']\n",
    "        TOP_CRITICS_RATING_IDX = movie_header_indeces['rtTopCriticsRating']\n",
    "        \n",
    "        movie_id, critic_rating, num_critic_ratings = line.split()[0], line.split()[TOP_CRITICS_RATING_IDX], line.split()[NUM_TOP_CRITICS_REVIEWS_IDX]\n",
    "        \n",
    "        if isfloat(num_critic_ratings) and (num_critic_ratings > 10) and isfloat(critic_rating):\n",
    "            critic_rating = float(critic_rating) / 10.0\n",
    "            movie_critic_ratings[movie_id] = critic_rating\n",
    "        \n",
    "    user_rating_header_indeces = {}\n",
    "    ratings = []\n",
    "    for line in open('data/grouplens/user_ratedmovies.dat'):\n",
    "        line = line.strip()\n",
    "        if not user_rating_header_indeces:\n",
    "            for i, column in enumerate(line.split('\\t')):\n",
    "                user_rating_header_indeces[column] = i\n",
    "            continue\n",
    "        \n",
    "        user_id, movie_id, rating = line.split()[0], line.split()[1], line.split()[2]\n",
    "        rating = float(rating) / 5.0\n",
    "        ratings.append(Rating(Rating=rating, User=user_id, Object=movie_id))\n",
    "    \n",
    "    return ratings, movie_critic_ratings\n",
    "\n",
    "ratings, movie_critic_ratings = get_data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rating = namedtuple('Rating', ['Rating', 'User', 'Object'])\n",
    "\n",
    "class RatingsGraph:\n",
    "    def __init__(self, ratings, gold_ratings, alpha):\n",
    "        self.alpha = alpha\n",
    "        self.ratings = ratings \n",
    "        self.gold_ratings_dict = gold_ratings #(object, gold_rating)\n",
    "        \n",
    "        self.user_set = set([rating.User for rating in self.ratings]) \n",
    "        self.users_lookup = {user: i for i, user in enumerate(self.user_set)}\n",
    "        self.object_set = set([rating.Object for rating in self.ratings])\n",
    "        self.objects_lookup = {obj: i for i, obj in enumerate(self.object_set)}\n",
    "\n",
    "        num_users, num_objects = len(self.user_set), len(self.object_set)\n",
    "        self.bias_diffs = []\n",
    "        self.adjacency = np.zeros([num_users, num_objects]) - 1 #set them to -1 bc rating can be 0\n",
    "        \n",
    "        for rating in self.ratings:\n",
    "            idx_user = self.users_lookup[rating.User]\n",
    "            idx_obj = self.objects_lookup[rating.Object]\n",
    "            self.adjacency[idx_user, idx_obj] = rating.Rating\n",
    "        \n",
    "        self.true_ratings = np.random.uniform(low = 0, high = 1, size = (num_objects, 1))\n",
    "        self.biases = np.random.uniform(low = -1, high = 1, size = (num_users,1))\n",
    "        \n",
    "        self.num_ratings_per_obj = np.sum(self.adjacency >= 0, axis = 0)\n",
    "        self.num_ratings_per_user = np.sum(self.adjacency >= 0, axis = 1)\n",
    "\n",
    "        self.gold_ratings = np.zeros([num_objects, 1]) - 1\n",
    "        for obj, gold_rating in self.gold_ratings_dict.iteritems():\n",
    "            try:\n",
    "                obj_idx = self.objects_lookup[obj]\n",
    "                self.gold_ratings[obj_idx] = gold_rating\n",
    "            except: continue\n",
    "    \n",
    "    def perform_single_iteration(self):\n",
    "        converged = True\n",
    "        alpha = self.alpha\n",
    "        \n",
    "        original_ratings = self.true_ratings.copy()\n",
    "        # subtract user biases from all ratings, but only where rating existed in first place!\n",
    "        updated_ratings = np.multiply((self.adjacency >= 0), self.adjacency - alpha*self.biases)\n",
    "        self.true_ratings = (1.0/self.num_ratings_per_obj)*\\\n",
    "            np.sum(np.maximum(np.zeros(self.adjacency.shape),\n",
    "                       np.minimum(np.ones(self.adjacency.shape), updated_ratings))\n",
    "            , axis = 0)\n",
    "            \n",
    "        max_diff = np.max(abs(original_ratings - np.expand_dims(self.true_ratings,1)))\n",
    "        if max_diff > 0.00001:  converged = False\n",
    "\n",
    "            \n",
    "        original_bias = self.biases.copy()\n",
    "        # subtract true ratings from given ratings - only where a rating was originally given!\n",
    "        updated_users = np.multiply((self.adjacency >= 0), self.adjacency - self.true_ratings)\n",
    "        self.biases = (1.0/self.num_ratings_per_user) * np.sum(updated_users, axis=1)\n",
    "            \n",
    "        self.true_ratings = np.expand_dims(self.true_ratings, axis=1) # to make the shapes work\n",
    "        self.biases = np.expand_dims(self.biases, axis=1) # to make the shapes work\n",
    "            \n",
    "        bias_diff = abs(original_bias - self.biases)\n",
    "        if np.max(bias_diff) > 0.00001:\n",
    "            converged = False\n",
    "        self.bias_diffs.append(np.sum(bias_diff))\n",
    "        \n",
    "        return converged\n",
    "    \n",
    "    def get_test_error(self):\n",
    "        num_gold_ratings = np.sum(self.gold_ratings >= 0)\n",
    "        pred_ratings = (self.gold_ratings >= 0)*self.true_ratings # if not in gold ratings, set to 0\n",
    "        gold_ratings_given = (self.gold_ratings >= 0) * self.gold_ratings\n",
    "        return 1.0/num_gold_ratings * np.sum(np.square(pred_ratings - gold_ratings_given))\n",
    "            \n",
    "    def iterate_until_convergence(self):\n",
    "        errors = []\n",
    "        converged = False\n",
    "        counter = 0\n",
    "        max_iter = 100\n",
    "        while not converged and counter < max_iter:\n",
    "            error = self.get_test_error()\n",
    "            print (error)\n",
    "            errors.append(error)\n",
    "            converged = self.perform_single_iteration()\n",
    "            counter += 1\n",
    "\n",
    "        return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.10798029703558\n",
      "61.5052357622723\n",
      "61.49367298914109\n",
      "61.493134930998515\n",
      "61.49308771285084\n"
     ]
    }
   ],
   "source": [
    "ratings_graph = RatingsGraph(ratings, movie_critic_ratings, alpha=0.1)\n",
    "errors = ratings_graph.iterate_until_convergence()\n",
    "alpha_01_y = ratings_graph.bias_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.209676444188126\n"
     ]
    }
   ],
   "source": [
    "ratings_graph = RatingsGraph(ratings, movie_critic_ratings, alpha=0.2)\n",
    "errors = ratings_graph.iterate_until_convergence()\n",
    "alpha_02_y = ratings_graph.bias_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings_graph = RatingsGraph(ratings, movie_critic_ratings, alpha=0.5)\n",
    "errors = ratings_graph.iterate_until_convergence()\n",
    "alpha_05_y = ratings_graph.bias_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alpha1_y = [1060.7027209712728, 8.151491760725987, 0.7153737296671119, 0.06850560075491723, 0.006667511431112653]\n",
    "# alpha2_y = [1070.5935889341972, 4.564030247992877, 0.612904383225149, 0.11645027071102854, 0.022635037211159174, 0.004417496078544927]\n",
    "# alpha3_y = [1053.1551336990312, 25.10273404110145, 7.154351826286142, 3.1423294052572497, 1.5036110680676322, 0.7318008354801494, 0.35723892532225704, 0.17449089566980958, 0.08524172566812642, 0.041643162313176836, 0.020344054518165375, 0.009938663773250384]\n",
    "\n",
    "plt.plot([i+1 for i in range(len(alpha_01_y))], [np.log(y) for y in alpha_01_y], 'orange', label='alpha = 0.1')\n",
    "plt.plot([i+1 for i in range(len(alpha_02_y))], [np.log(y) for y in alpha_02_y], '-b', label='alpha = 0.2')\n",
    "plt.plot([i+1 for i in range(len(alpha_05_y))], [np.log(y) for y in alpha_05_y], '-g', label='alpha = 0.5')\n",
    "plt.legend()\n",
    "plt.title('Bias Convergence Error by Epoch')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Log Bias Convergence Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_ratings_df = pd.read_table('data/grouplens/user_ratedmovies.dat', sep=\"\\t\")\n",
    "movie_ratings_df = pd.read_table('data/grouplens/movies.dat', sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
